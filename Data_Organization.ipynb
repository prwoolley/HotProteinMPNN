{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import os\n",
    "from bioservices import UniProt\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading HotProtein Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the S_target pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_labels\n",
       "3    63126\n",
       "1    28002\n",
       "4    25310\n",
       "2    24286\n",
       "0     5120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('S/S_target.pkl', 'rb') as f:\n",
    "    S_target = pkl.load(f)\n",
    "S_target_train = pd.DataFrame({key: S_target[key] for key in ['train_names', 'train_labels']})\n",
    "S_target_test = pd.DataFrame({key: S_target[key] for key in ['test_names', 'test_labels']})\n",
    "\n",
    "with open('S/S_target_classification.pkl', 'rb') as f:\n",
    "    S_target_classification = pkl.load(f)\n",
    "S_target_train_classification = pd.DataFrame({key: S_target_classification[key] for key in ['train_names', 'train_labels']})\n",
    "S_target_test_classification = pd.DataFrame({key: S_target_classification[key] for key in ['test_names', 'test_labels']})\n",
    "\n",
    "\n",
    "S_target_train_classification['train_labels'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only saving the S_target names that have a downloaded AF2 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_target_concat = pd.concat([S_target_train.rename(columns={'train_names': 'names', 'train_labels': 'labels'}), \n",
    "                             S_target_test.rename(columns={'test_names': 'names', 'test_labels': 'labels'})])\n",
    "S_target_classification_concat = pd.concat([S_target_train_classification.rename(columns={'train_names': 'names', 'train_labels': 'labels'}), \n",
    "                             S_target_test_classification.rename(columns={'test_names': 'names', 'test_labels': 'labels'})])\n",
    "S_target_AF2 = os.listdir(\"/stor/work/Ellington/ProteinMPNN/HotProtein/S/AF2/CIF\")\n",
    "S_target_AF2 = pd.Series(S_target_AF2)\n",
    "S_target_AF2 = S_target_AF2.str.split('-').str[1]\n",
    "S_target_names_not_in_AF2 = S_target_concat[~S_target_concat['names'].isin(S_target_AF2)]['names']\n",
    "\n",
    "S_target_concat = S_target_concat[~S_target_concat['names'].isin(S_target_names_not_in_AF2)]\n",
    "S_target_classification_concat = S_target_classification_concat[~S_target_classification_concat['names'].isin(S_target_names_not_in_AF2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading ProteinMPNN Training Dataset Info\n",
    "\n",
    "We want to ultimately remove HotProtein entries that are represented in the ProteinMPNN training dataset, to eliminate data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Map ProteinMPNN PDB IDs to UniProt Accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m accessions:\n\u001b[1;32m     11\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m item)\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m uniprot\u001b[38;5;241m.\u001b[39mmapping(fr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDB\u001b[39m\u001b[38;5;124m\"\u001b[39m, to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniProtKB\u001b[39m\u001b[38;5;124m\"\u001b[39m,query\u001b[38;5;241m=\u001b[39mpdb)  \u001b[38;5;66;03m# ACC for UniProtKB AC (identifier)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m[]:\n\u001b[1;32m     14\u001b[0m     accession \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimaryAccession\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/software/miniconda3/envs/3DBeacons/lib/python3.11/site-packages/bioservices/uniprot.py:493\u001b[0m, in \u001b[0;36mUniProt.mapping\u001b[0;34m(self, fr, to, query, polling_interval_seconds, max_waiting_time, progress)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: batches, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailedIds\u001b[39m\u001b[38;5;124m\"\u001b[39m: fails}\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(polling_interval_seconds)\n\u001b[1;32m    494\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    495\u001b[0m waiting_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m polling_interval_seconds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proteinmpnn_data = pd.read_csv('/stor/work/Ellington/ProteinMPNN/training/ProteinMPNN_training_data/pdb_2021aug02/list.csv')\n",
    "proteinmpnn_data = proteinmpnn_data['CHAINID'].str.split('_').str[0].unique()\n",
    "proteinmpnn_data = [x.upper() for x in proteinmpnn_data]\n",
    "accessions = []\n",
    "\n",
    "uniprot = UniProt()\n",
    "for pdb in proteinmpnn_data:\n",
    "    if len(accessions) % 100 == 0:\n",
    "        with open('/stor/work/Ellington/ProteinMPNN/HotProtein/ProteinMPNN_TrainingData_UniProtAccessions.txt', 'w') as f:\n",
    "            for item in accessions:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "    results = uniprot.mapping(fr=\"PDB\", to=\"UniProtKB\",query=pdb)  # ACC for UniProtKB AC (identifier)\n",
    "    if results['results']!=[]:\n",
    "        accession = results['results'][0]['to']['primaryAccession']\n",
    "        accessions.append(accession)\n",
    "    else:\n",
    "        continue\n",
    "with open('/stor/work/Ellington/ProteinMPNN/HotProtein/ProteinMPNN_TrainingData_UniProtAccessions.txt', 'w') as f:\n",
    "            for item in accessions:\n",
    "                f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the ProteinMPNN training dataset overlap with HotProtein?\n",
    "\n",
    "Given the downloaded UniProt IDs mapped to the ProteinMPNN training data, does it overlap with HotProtein in...\n",
    "* ID?\n",
    "* Sequence? (requires MMSeqs2 and FASTA files for ProteinMPNN training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n"
     ]
    }
   ],
   "source": [
    "mpnn_uniprot = pd.read_csv('/stor/work/Ellington/ProteinMPNN/HotProtein/ProteinMPNN_TrainingData_Unique_UniProtAccessions.txt', header=None)\n",
    "S_target_AF2\n",
    "\n",
    "overlaps = S_target_concat[S_target_concat['names'].isin(mpnn_uniprot[0])]['names']\n",
    "print(len(overlaps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "526 structures directly overlap between the two sets. We'll mark these structures and move on to sequence fetching.\n",
    "\n",
    "Now, we want to see if the structures from the MPNN set overlap in sequence content. This will be done via MMSeqs2. First, we need to acquire the FASTA sequences from the MPNN dataset (~40k structures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_fasta_directory = '/stor/work/Ellington/ProteinMPNN/HotProtein/ProteinMPNN_TrainingData_Fasta'\n",
    "\n",
    "# Base URL for UniProt REST API\n",
    "base_url = \"https://rest.uniprot.org/uniprotkb/\"\n",
    "\n",
    "# Retrieve and save Fasta files\n",
    "for accession in mpnn_uniprot[0]:\n",
    "    url = f\"{base_url}{accession}.fasta\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for error status codes\n",
    "        with open(f\"{mpnn_fasta_directory}/{accession}.fasta\", \"w\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Saved Fasta file for {accession}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error retrieving {accession}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving {accession}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing the fasta files for each split into subdirectories\n",
    "\n",
    "s2c2 = temps [<45,45<] map to classes [[0,1,2],[3,4]]\n",
    "\n",
    "s2c5 = temps [-20:5,5:25,25:45,45:75,75<] maps to classes [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m uniprot\u001b[38;5;241m.\u001b[39mmapping(fr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDB\u001b[39m\u001b[38;5;124m\"\u001b[39m, to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniProtKB\u001b[39m\u001b[38;5;124m\"\u001b[39m,query\u001b[38;5;241m=\u001b[39mproteinmpnn_data[\u001b[38;5;241m27\u001b[39m])  \u001b[38;5;66;03m# ACC for UniProtKB AC (identifier)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[0;32m----> 4\u001b[0m     accession \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimaryAccession\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     accessions\u001b[38;5;241m.\u001b[39mappend(accession)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "uniprot = UniProt()\n",
    "results = uniprot.mapping(fr=\"PDB\", to=\"UniProtKB\",query=proteinmpnn_data[27])  # ACC for UniProtKB AC (identifier)\n",
    "if results['results']!=[]:\n",
    "    accession = results['results'][0]['to']['primaryAccession']\n",
    "    accessions.append(accession)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
